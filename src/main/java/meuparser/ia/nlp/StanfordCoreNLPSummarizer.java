package meuparser.ia.nlp;

import edu.stanford.nlp.pipeline.*;
import edu.stanford.nlp.ling.*;
import edu.stanford.nlp.util.*;
import java.util.*;
import java.util.stream.Collectors;

/**
 * Sumarizador baseado em Stanford CoreNLP - VERS√£o CORRIGIDA
 * Configura√ß√£o simplificada que funciona sem modelos espec√≠ficos
 */
public class StanfordCoreNLPSummarizer implements INLPSummarizer {

    private StanfordCoreNLP pipeline;
    private boolean initialized = false;
    private final Object initLock = new Object();

    // Evita tentativas repetidas ap√≥s falha permanente
    private static volatile boolean permanentlyDisabled = false;

    /**
     * Configura√ß√£o B√ÅSICA que funciona sem modelos espec√≠ficos de portugu√£¬™s
     */
    private Properties createPipelineProperties() {
        Properties props = new Properties();

        // REMOVE configura√ß√£¬µes problem√°ticas de portugu√£¬™s:
        // - N√£o usar "tokenize.language=Portuguese"
        // - N√£o usar modelos espec√≠ficos que podem n√£o existir

        // Pipeline m√≠nimo mas funcional
        props.setProperty("annotators", "tokenize,ssplit");

        // Configura√ß√£¬µes b√°sicas
        props.setProperty("threads", "1");
        props.setProperty("outputFormat", "text");

        return props;
    }

    @Override
    public void initialize() throws Exception {
        synchronized (initLock) {
            if (initialized || permanentlyDisabled) return;

            System.out.println("Inicializando Stanford CoreNLP...");
            long startTime = System.currentTimeMillis();

            try {
                // Primeira tentativa: configura√ß√£o b√°sica
                Properties props = createPipelineProperties();
                pipeline = new StanfordCoreNLP(props);
                initialized = true;

                long initTime = System.currentTimeMillis() - startTime;
                System.out.printf("‚úÖ Stanford CoreNLP inicializado em %d ms\n", initTime);

            } catch (Exception e) {
                System.err.println("‚ùå Falha ao inicializar Stanford CoreNLP: " + e.getMessage());

                // Se falhar, desabilita permanentemente para evitar logs repetidos
                permanentlyDisabled = true;
                pipeline = null;
                initialized = false;

                System.out.println("‚ö† Stanford CoreNLP desabilitado, usando algoritmo extrativo");
            }
        }
    }


    @Override
    public String summarize(String content, int maxSentences) {
        if (!ensureInitialized()) {
            return fallbackSummarize(content, maxSentences);
        }

        long startTime = System.currentTimeMillis();

        try {
            // Pr√£¬©-processamento
            String cleanContent = preprocessContent(content);
            if (cleanContent.length() < 100) return cleanContent;

            // An√°lise com Stanford CoreNLP (b√°sica)
            Annotation document = new Annotation(cleanContent);
            pipeline.annotate(document);

            // Extra√ß√£o de senten√ßas b√°sica
            List<CoreMap> sentences = document.get(CoreAnnotations.SentencesAnnotation.class);

            if (sentences == null || sentences.isEmpty()) {
                return fallbackSummarize(content, maxSentences);
            }

            // √∞≈∏‚Äù¬ß CORRE√á√£o CR√çTICA: Calcular limite baseado no tamanho do conte√£¬∫do
            int targetSentenceCount = calculateAdaptiveSentenceCount(content.length(), maxSentences);
            int limit = Math.min(targetSentenceCount, sentences.size());

            System.out.printf("üìä Stanford CoreNLP: %d senten√ßas dispon√≠veis ‚Üí selecionando %d senten√ßas (maxSentences: %d)\n",
                    sentences.size(), limit, maxSentences);

            // ‚úÖ Seleciona senten√ßas baseado no limite calculado
            String summary = sentences.stream()
                    .limit(limit)
                    .map(CoreMap::toString)
                    .collect(Collectors.joining(" "));

            long processingTime = System.currentTimeMillis() - startTime;
            System.out.printf("üìä Stanford CoreNLP: %d chars ‚Üí %d chars em %d ms\n",
                    content.length(), summary.length(), processingTime);

            return summary;

        } catch (Exception e) {
            System.err.println("‚ùå Erro no Stanford CoreNLP: " + e.getMessage());
            return fallbackSummarize(content, maxSentences);
        }
    }

    /**
     * CORRIGIDO: Calcula n√£¬∫mero mais conservador de senten√ßas para reduzir compress√£o excessiva
     */
    private int calculateAdaptiveSentenceCount(int contentLength, int maxSentences) {
        // ‚úÖ N√öMEROS EXTREMAMENTE REDUZIDOS para usu√°rios Braille
        if (contentLength > 30000) {
            // Wikipedia: apenas 2-3 senten√ßas para ~600 chars
            return Math.min(3, maxSentences);   // DRASTICAMENTE REDUZIDO
        } else if (contentLength > 5000) {
            // Brasil Escola: apenas 2-3 senten√ßas para ~600 chars
            return Math.min(3, maxSentences);   // DRASTICAMENTE REDUZIDO
        } else {
            // G1: apenas 1-2 senten√ßas para ~400 chars
            return Math.min(2, maxSentences);   // DRASTICAMENTE REDUZIDO
        }
    }


    @Override
    public List<String> extractKeysentences(String content, int count) {
        if (!ensureInitialized()) {
            return Arrays.asList(fallbackSummarize(content, count).split("\\. "));
        }

        try {
            Annotation doc = new Annotation(preprocessContent(content));
            pipeline.annotate(doc);

            List<CoreMap> sentences = doc.get(CoreAnnotations.SentencesAnnotation.class);
            if (sentences == null) return new ArrayList<>();

            return sentences.stream()
                    .limit(count)
                    .map(CoreMap::toString)
                    .collect(Collectors.toList());
        } catch (Exception e) {
            return Arrays.asList(fallbackSummarize(content, count).split("\\. "));
        }
    }

    @Override
    public double calculateSentenceRelevance(String sentence, String fullContext) {
        return 0.5; // Valor neutro, pois n√£o temos an√°lise avan√ßada
    }

    @Override
    public NLPProviderInfo getProviderInfo() {
        return new NLPProviderInfo(
                "Stanford CoreNLP",
                "4.5.0",
                "Pipeline b√°sico (tokenize, ssplit) - sem modelos PT",
                false, false, 256_000_000L
        );
    }

    @Override
    public boolean isReady() {
        return initialized && pipeline != null && !permanentlyDisabled;
    }

    @Override
    public void cleanup() {
        pipeline = null;
        initialized = false;
        System.out.println("üßπ Stanford CoreNLP cleanup conclu√≠do");
    }

    // M√£¬©todos auxiliares
    private boolean ensureInitialized() {
        if (permanentlyDisabled) return false;

        if (!initialized) {
            try {
                initialize();
            } catch (Exception e) {
                return false;
            }
        }
        return initialized;
    }

    private String preprocessContent(String content) {
        return content
                .replaceAll("\\[.*?\\]", "")
                .replaceAll("\\s+", " ")
                .trim();
    }

    private String fallbackSummarize(String content, int maxSentences) {
        String[] sentences = content.split("(?<=[.!?])\\s+");
        int limit = Math.min(maxSentences, sentences.length);
        return String.join(" ", Arrays.copyOf(sentences, limit));
    }
}